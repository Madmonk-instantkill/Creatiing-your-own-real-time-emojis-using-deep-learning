# Creatiing-your-own-real-time-emojis-using-deep-learning

Emojis have become the new language of today’s world.Gone  are  the  days  when  it  was  just  used  for  fun,  today,its  more  often  used  to  express  ones  feeling  while  textingand  thus  helps  in  conveying  feeling  in  more  precise  way.There was a project on Kaggle in 2016-2017 in which, peo-ple were asked to make a model for human emotion detec-tion.  The data-set used was Facial Expression RecognitionData-set. There were 7 human emotions categories in data-set namely: angry, happy, sad, scared, surprised, disgustedand natural and people were asked to train their models todetect these emotions.  The training set consisted of about28709 images of 7 categories and test data set had 7000images.  In this project, I am going to take this competitiona bit further. Instead of depicting the emotions of a station-ary picture, I will be capturing images in real time and inparallel predict their emotions.  I will try to use one of themodels  which  we  used  in  project-1,  a  convolution  neuralnetwork.   As I got good accuracies in VGG-16,the archi-tecture used will also be VGG-16.   Of course,  as per ourlearning in project 1, I will try to make lot of changes in thismodel’s  architecture)  and  hence  makes  sure  that  it  fits  toour data-set. Ones I get a good accuracy, (here we assumean accuracy above 60 percent can be considered a good ac-curacy and will work), I will proceed to the next stage.  Iwill then apply few concepts of computer vision to captureimages from real time, (webcam in this case) and in paral-lel detect the emotions.  I will use two face detection tech-niques, ie open CV’s Cascade classifier and Deep learningpre trained model ie MTCNN. We will compare the perfor-mance of both of these face detection techniques and basedon the outcome,  I will select one.   Apart from that,  I willalso discuss the working technique behind these methods inbrief and understand what are their advantages and disad-vantages. Finally, ones I am able to detect faces , I will sendevery frame to our previously trained model and predict itsemotion.  This will be then linked to seven different emojis(which too represent seven emotions) and the emoji corre-sponding to the detected emotion will be displayed.  Pleasenote that its not a major project.  The aim of this project isto put in use, the concepts of deep learning and computervision that I have learned this semester.

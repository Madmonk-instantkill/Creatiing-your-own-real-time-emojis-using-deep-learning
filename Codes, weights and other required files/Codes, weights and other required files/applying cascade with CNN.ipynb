{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Cascade\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten,LeakyReLU\n",
    "from keras.layers import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#1\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),input_shape=(48,48,1)))\n",
    "\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "#2\n",
    "model.add(Conv2D(32, kernel_size=(3, 3)))\n",
    "\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.20))\n",
    "#3\n",
    "model.add(Conv2D(64, kernel_size=(3, 3)))\n",
    "\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "#\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#4\n",
    "model.add(Conv2D(64, kernel_size=(3, 3)))\n",
    "\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512))\n",
    "\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.load_weights('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", \n",
    "                        3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}\n",
    "\n",
    "emoji_dist={0:\"./emojis/chopper/angry.jpg\",\n",
    "            1:\"./emojis/chopper/disgusted.jpg\",2:\"./emojis/chopper/fearful.jpg\",\n",
    "            3:\"./emojis/chopper/happy.jpg\",\n",
    "            4:\"./emojis/chopper/neutral.jpg\",\n",
    "            5:\"./emojis/chopper/sad.jpg\",6:\"./emojis/chopper/surprised.jpg\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value=2\n",
    "predicted_emotion=\"angry\"\n",
    "#def vid():\n",
    "rod=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    m1,frame1=rod.read()\n",
    "    if not m1:\n",
    "        break\n",
    "    #frame1=cv2.cvtColor(frame1,cv2.COLOR_BGR2RGB)\n",
    "    grayed=cv2.cvtColor(frame1,cv2.COLOR_RGB2GRAY)\n",
    "    face=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    #grayed=cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    cords=face.detectMultiScale(grayed,1.3,5)\n",
    "    for (a,b,c,d) in cords:\n",
    "        cv2.rectangle(frame1,(a,b),(a+c,b+d),(255,0,0),2)\n",
    "        cropped=grayed[b:b+d,a:a+c]\n",
    "        sample=np.expand_dims(np.expand_dims(cv2.resize(cropped,(48,48)),axis=2),axis=0)\n",
    "        q=model.predict(sample)\n",
    "        value=np.argmax(q)\n",
    "        predicted_em=emotion_dict[value]\n",
    "        cv2.putText(frame1,predicted_emotion,(a+20, b-60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    cv2.imshow(\"frame1\",cv2.resize(frame1,(1200,860),interpolation = cv2.INTER_CUBIC))\n",
    "    ang=cv2.imread(emoji_dist[value])\n",
    "    cv2.imshow(\"emoji\",ang) \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference: \n",
    "    \n",
    "#the idea for this project was from this site and its used to understand about how to proceed in this project. However ones the concept was understood, then the main project was developed on own "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
